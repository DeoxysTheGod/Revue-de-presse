<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <title>Revue de presse</title>
    <link rel="stylesheet" href="style.css">
</head>
<body>
<section>
    <h1>Revue de presse sur le "deepfake"</h1>

    <article>
        <h1>Un "deepfake" capable de duper les présidents</h1>

        <img id="img_article_1" src="img/francoisHollande.jpg" alt="François Hollande">

        <p>
            Récemment, François Hollande, ex-président français, s'est entretenu avec Petro Porochenko ex-président
            russe. C'est donc pendant une discussion d'environ 15 minutes que les deux ex-dirigeant ont échangé sur
            la situation en Ukraine et sur les accords de Minsk.
        </p>
        <p>
            Cependant, cette discussion avec l'ex-président russe n'était pas réel du moins pas entièrement.
        </p>
        <p>
            En effet, François Hollande s'est bien entretenu avec quelqu'un mais ce n'était pas Petro Porochenko, il
            s'agissait tout simplement d'un "deepfake" réaliser par deux humoristes russes.
        </p>
        <p>
            Néanmoins, une telle tromperie n'est pas sans conséquences, car Hollande, ne sachant pas cela, a révélé des
            informations confidentielles sur les accords de Minsk. Cette conversation s'étant retrouvé sur les réseaux
            sociaux,
            nombreux sont les internautes à réagir au propos de l'ex président.
        </p>

        <a href="https://www.lunion.fr/id473653/article/2023-04-09/francois-hollande-piege-par-deux-humoristes-russes">Article
            de L'union</a>

        <h2>Ce que m'a appris l'article</h2>
        <p>
            Cette article montre que les "deepfake" sont de plus en plus courant
            et réaliste, même des dirigeants d'État se font piéger. C'est également
            préoccupant, car cette situation peut se reproduire et avoir des conséquences
            plus graves.
        </p>
    </article>
    <article>
        <h1>"Deepfake", on reste sans voix devant sa voix</h1>

        <img src="img/deepfakeVoix.jpg" alt="visage virtuel qui parle">

        <p>
            ElevenLabs est un simulateur de voix, très utile pour créer des voix. Il a cependant été détourné de ses
            fonctions par un grand nombre d'utilisateurs, car
            ce logiciel est récemment devenu accessible aux grand public. Il y a donc rapidement eu des dérives souvent
            à caractère raciste, homophobe, etc.
        </p>
        <p>
            On a par exemple pu entendre Emma Watson en train de lire <em>Mein Kampf</em>.<br>
            En effet, il est facile avec tous ces outils de créer une vidéo de toute pièce de manière simple, rapide,
            mais surtout ultra-réaliste.
        </p>
        <p>
            Cette outils a été développer par ElevenLabs, une start-up anglaise.
            Ils utilisent l'intelligence artificielle afin de récréer une voix réaliste.
        </p>
        <p>
            Néanmoins, la start-up, a constaté que des utilisations abusives de leur outil
            sont de plus en plus courante. Les concepteurs de ce logiciel ont donc annoncé
            qu'ils voulaient durcir le processus d'identification en mettant en place des mesures
            de protection supplémentaires. En vérifiant les auteurs des échantillons soumis
            et de procéder à des vérifications manuelles.
        </p>

        <a href="https://www.lefigaro.fr/secteur/high-tech/deepfake-le-simulateur-de-voix-elevenlabs-s-inquiete-des-abus-20230131">Article
            du Figaro</a>

        <h2>Ce que m'a appris l'article</h2>
        <p>
            Cette article montre qu'il est désormais possible de recréer de
            manière très réaliste une voix humaine, utile dans les films pour
            recréer les voix d'acteurs décéder, mais comme toutes technologies,
            il y a des dérives. Il est cependant, difficile de les repérer.
        </p>
    </article>
    <article>
        <h1>Quand la pop culture rentre dans la mode</h1>

        <img src="img/balenciagaHarryPotterFake.jpg" alt="personnage de harry potter dans un défilé balenciaga">

        <p>
            Grace à ChatGPT, Midjourney et D-ID, il est possible depuis quelque semaine
            de voir les personnages de "Harry Potter", "Le seigneur des Anneaux", etc
            en train de faire des défilés de mode pour balenciaga. Des vidéos à première
            vue drôles, à l'exception du fait que toutes les vidéos chantent les louanges de la
            marque balenciaga.
        </p>
        <p>
            Plusieurs "deepfake" promouvant la marque ont fait le tour d'internet.
            Cependant, la marque n'en est pas la source. Ce sont les internautes qui leur
            octroient une publicité gratuite surtout avec les scandales actuelle de la marque.
        </p>
        <p>
            Ces vidéos sont donc bien innocentes, mais cela pose des questions sur la
            potentielle utilisation malsaine de ces outils qui, en effet, permettent de
            créer très facilement des deepfakes. ElevenLab qui permet de refaire des voix à partir
            d'un échantillon de 1 minute a d'ailleurs supprimé l'accès gratuit à son
            logiciel.
        </p>

        <a href="https://phototrend.fr/2023/04/video-deepfake-harry-potter-by-balenciaga/">Article de PhotoTrend</a>

        <h2>Ce que m'a appris l'article</h2>
        <p>
            Cette article montre la puissance des intelligences artificielles
            comme Midjourney, CHatGPT et d'autre. Dans ce cas ce n'est que pour
            créer du contenu divertissant. Mais cette puissance mal utilisée
            peut créer des problèmes important.
        </p>
    </article>
    <article>
        <h1>"Deepfake", des utilisations diverses</h1>
        <img id="img_article_4" src="img/deepfakeSerie.jpg" alt="poster d'une série deepfake">
        <p>
            Le "deepfake", permet de recréer des visages et des voix de
            manière très réaliste. De plus en plus utilisé dans les documentaires
            ou le cinéma afin de rajeunir les stars ou recréer la voix
            d'acteur décédé. Cependant, les outils permettant ces prouesses
            techniques sont désormais accessible au grand public et souvent
            utilisées à des fins malveillantes.
        </p>
        <p>
            On peut par exemple voir un Barack Obama tenir des propos insultant
            ou des séries regroupant Rihanna, Beyoncé et Andy Murray sans qu'ils
            aient participé à celle-ci. Pire encore, Volodymyr Zelensky,
            qui ordonne à ses soldats de déposé les armes.
        </p>
        <p>
            Les "deepfake" font également des victimes. En France par exemple
            "Jujufitcats" une youtubeuse fitness, reçoit des photos d'elles dénudée
            qu'elle n'a jamais prises.
        </p>
        <a href="https://www.francetvinfo.fr/replay-jt/france-2/20-heures/technologie-propagande-harcelement-les-derives-du-deepfake_5642132.html">Article de Franceinfo</a>

        <h2>Ce que m'a appris l'article</h2>
        <p>
            Cette article montre une des utilisations de l'intelligence artificielle.
            Il est désormais possible de faire jouer des acteurs dans des films ou
            série alors que l'acteur n'était pas là. Une question reste sur la légalité
            de cette pratique, car cela signifie que des films entiers pour être tourné
            sans même payer d'acteur.
        </p>
    </article>
    <article>
        <h1>Un journal télévisé fictif</h1>
        <img src="img/fausseEmissionTV.jpg" alt="personne devant un écran qui diffuse des informations">
        <p>
            De faux présentateurs télé, un faux plateau, de fausse info, en bref,
            une fausse émission télé. En effet, tout est générés par une intelligence
            artificielle et les vidéos sont publiées sur les réseaux sociaux afin de
            promouvoir des idées pro-Pékin dans l'intérêt du Parti communiste chinois.
        </p>
        <p>
            Ce trucage et bien d'autre, montre le problème que pause ces "deepfake"
            grandissant dans le domaine de l'information. Car grâce à ces technologies
            de fausses informations peuvent être véhiculé de manière très convaincante.
        </p>
        <p>
            l'hypertrucage est donc un danger, et les entreprises développant des outils
            de "deepfake" essaient de lutter au maximum contre ces utilisations malveillantes
            en durcissant le système d'authentification et en obtenant l'identité réelle
            de leurs utilsateurs.
        </p>
        <a href="https://www.bfmtv.com/tech/intelligence-artificielle/pour-la-premiere-fois-un-deepfake-a-ete-utilise-dans-une-video-de-propagande-pro-pekin_AD-202302080132.html">Article de BFMTV</a>

        <h2>Ce que m'a appris l'article</h2>
        <p>
            Cette article montre une des utilisations néfaste et dangereuse de l'IA
            avec la diffusion de fausses informations en faisant croire qu'elles sont
            encadrées et réels alors qu'il n'en ait rien.
        </p>
    </article>
    <article>
        <h1>Facebook fait de la pub pour du "deepfake" pornographique</h1>
        <img src="img/pornoFacebookDeepfake.jpeg" alt="femme en lingerie sexy avec le visage flouté">
        <p>
            Depuis plusieurs jours, des publicités promouvant une application de
            "deepfake" qui incite à faire des montages de vidéos pornographiques
            mettant en scène des célébrités, apparaissent sur tous les réseaux sociaux de Meta.
        </p>
        <p>
            Cette application nommée "FaceMega", ne se revendiquent pas en tant qu'application
            pour faire des montages pornographiques, cependant, comme le montre leur publicité
            sur Facebook, on peut le comprendre comme tel. Elle était d'ailleurs disponible
            sur "Apple Store" et "Play store" gratuitement. Elle est désormais payante
            pour 8$/semaines.
        </p>
        <p>
            On peut très bien imaginer l'utilisation que peuvent en faire les gens.
            Par exemple pour de l'intimidation scolaire ou pour nuir à une personne
            dans son travail par exemple. Car il suffit d'une simple photo pour réaliser
            ce genre de deefake.
        </p>
        <p>
            D'après l'analyste Genevieve Oh, le trafic et la consultation de sites web spécialisés
            dans les deepfakes pornographiques a littéralement explosé. Cette augmentation
            n'est pas dû au hasard, elle provient de la plateforme Twitch, après qu'un
            streamer a diffusé des montages pornographiques de streameuses célèbres.
            Répendant ainsi l'existence de cette pratique au grand public.
        </p>

        <a href="https://www.phonandroid.com/deepfake-la-demande-pour-les-montages-pornographiques-explosent-des-pubs-apparaissent-sur-facebook.html">Article de Phonandroid</a>

        <h2>Ce que m'a appris l'article</h2>
        <p>
            Cette article montre selon moi l'inaction et la non-réactivité de certains
            réseaux sociaux sur le contrôle de la publicité, mais également les dérives
            de l'intelligence artificielle et le danger qu'elle représente pour
            les personnalitées publiques, mais également anonyme avec des outils puissants
            pour appuyer le harcèlement scolaire.
        </p>
    </article>
    <article>
        <h1>Le pape abandonne sa soutane pour une doudoune</h1>
        <img src="img/papeDoudoune.jpg" alt="Le pape qui porte une grosse doudoune blanche">
        <p>
            Depuis quelques jours, sur les réseaux sociaux, il est possible
            de voir le Pape porter une grosse doudoune blanche. Cette image
            est fausse et a été généré par l'intelligence artificielle Midjourney.
        </p>
        <p>
            Comme a pu le dire la célébrité américaine Chrissy Teigen, il est désormais
            très difficile de faire la différence entre une vraie image et une image
            générée par une intelligence artificielle ce qui reflètent le ressenti de
            beaucoup d'internautes.
        </p>
        <p>
            Même si ces générations ne sont pas parfaites, il faut regarder dans
            les détails pour s'appercevoir de la supercherie. Mais comme notre système
            d'information repose sur le scrolling, on ne prête que trop rarement aux détails
            d'une image. De plus les intelligences artificielles s'améliorent
            de plus en plus, ce qui à terme mènera à des images parfaites et
            indésselable.
        </p>

        <a href="https://www.clubic.com/technologies-d-avenir/intelligence-artificielle/actualite-462786-ce-pape-en-doudoune-est-un-deepfake-mais-classe-mais-deepfake-mais.html">Article de Clubic</a>

        <h2>Ce que m'a appris l'article</h2>
        <p>
            Le "deepfake" est ici à but récréatif, mais cela montre l'amélioration
            des technologies de "deepfake" et leur puissance. J'ai été abasourdis
            par le réalisme de ces trucages.
        </p>
    </article>
    <article>
        <h1>TikTok l'exterminateur de "deepfake"</h1>
        <img src="img/tiktok.jpg" alt="main qui tient un téléphone avec tiktok ouvert">
        <p>
            Le réseau social a en effet, annoncé durcir ses règles vis-a-vis
            des contenus généré par des intelligences artificielles afin
            de faire des "deepfake".
        </p>
        <p>
            La plateforme empeché déjà la publication de contenus susceptibles
            d'induire les utilisateurs en erreur sur des évenements réels.
            Désormais, les "deepfake" concernant une personne anonyme et reproduisant
            sa voix ou son visage seront interdits. Quant aux personnalités publiques
            les médias synthétiques seront interdit s'ils sont diffamatoires ou haineux.
        </p>
        <p>
            De plus, lorsqu'un "deepfake" qui respecte les règles sera posté, il devra
            être mentionné que ce contenu a été modifié.
        </p>

        <a href="https://leclaireur.fnac.com/article/262795-tiktok-durcit-ses-regles-contre-les-deepfakes/">Article de l'Éclaireur Fnac</a>

        <h2>Ce que m'a appris l'article</h2>
        <p>
            Cette article montre que certains réseaux sociaux, dont TikTok prennent
            part à la lutte contre les "deepfake" et la désinformation. C'est donc
            pour moi une bonne nouvelle pour l'avenir de l'information.
        </p>
    </article>
    <article>
        <h1>Un directeur de collège raciste</h1>
        <img src="img/directeurRaciste.jpg" alt="image d'un directeur qui tient des propos raciste - c'est un deepfake">
        <p>
            Sur la plateforme TikTok, des vidéos d'un directeur de collège tenant
            des propos racistes circulent depuis quelque jours. Ce sont en réalité
            des "deepfake" réalisé par trois étudiants d'un collège voisin qui sont
            à l'origine de ces vidéos.
        </p>
        <p>
            L'histoire est cependant plus compliqué, car des parents d'élèves ce sont
            plains que ces images sont le reflet d'un problème plus large de comportement
            raciste dans les écoles du district.
        </p>
        <p>
            Les vidéos ont été signalées aux autorités scolaires le 12 février.
            Ceux-ci ont déclaré que les auteurs de ces trucages seront traités
            conformément au code de conduite du district.
        </p>
        <p>
            Les parents ont tous de même soutenu le fait que la menace ait été
            sousestimé et qu'il aurait fallu prendre des mesures de sécurité.
        </p>

        <a href="https://www.bfmtv.com/tech/sur-tik-tok-un-deepfake-fait-tenir-des-propos-racistes-au-directeur-d-un-college_AV-202303090354.html">Article de BFMTV</a>

        <h2>Ce que m'a appris l'article</h2>
        <p>
            Cette article montre le danger que peut avoir l'utilisation de "deepfake"
            dans le cadre scolaire. Cette situation aurait pu très mal tourner et on peut
            voir que, même si cette vidéo a rapidement été démasqué, des conséquences
            demeurent sur le moral des parents élèves.
        </p>
    </article>
    <article>
        <h1>Elon Musk, le visionnaire drogué</h1>
        <img src="img/elonMuskDrogue.jpg" alt="Elon Musk avec un visage très enjoué">
        <p>
            Le patron de Tesla et Twitter avoue se droguer afin de créer le
            design de ses voitures. Au vu du caractère de celui-ci, beaucoup
            de personnes ont cru à sa déclaration face caméra. Cependant, cette
            vidéo n'est en fait pas réel, il s'agit d'un "deepfake".
        </p>
        <p>
            Il est néanmoins très facile de déceler le fake puisque la personne
            ayant posté cette vidéo (plattepus) est en fait un habitué de la vidéo
            de synthèse, avec de nombreuse autre vidéo du milliardaire dans des situations
            caucasses.
        </p>
        <p>
            Il n'y a même pas besoin d'aller jusqu'à chercher les sources de cette vidéo
            pour déceler le fake, car en regardant de plus près, on peut voir que
            la bouche d'Elon Musk ne se ferme pas et que sa voix à un léger décalage
            avec l'image.
        </p>

        <a href="https://www.tf1info.fr/international/elon-musk-avoue-etre-drogue-la-video-du-patron-de-twitter-et-tesla-devenue-virale-sur-tiktok-etait-un-deepfake-2245110.html">Article de TF1 INFO</a>

        <h2>Ce que m'a appris l'article</h2>
        <p>
            Ici le "deepfake" est utilisé surtout pour faire rire, mais cela montre
            que cette technologie peut être utilisée à des fins plus malveillantes.
        </p>
    </article>
    <article>
        <h1>5 Moyens de débusquer le "deepfake"</h1>
        <img src="img/trumpDeepfake.jpg" alt="image d'un deepfake de trump avec un cercle qui montre un problème sur l'image">
        <p>
            En ce moment les vidéos ou images de synthèse pullulent sur internet,
            il devient donc important d'éduquer notre œil à partir à la chasse
            au fake.
        </p>
        <p>
            La première étape est de vérifier la qualité, les "deepfake" surfont
            souvent le flou d'arrière-plan, la qualité du premier et souvent extrement
            nette alors que l'arrière-plan est flou.
        </p>
        <p>
            La deuxième étape est de vérifier les ombres, en effet, elles sont
            souvent inexistante, pas au bon endroit ou pas avec les bonnes
            proportions.
        </p>
        <p>
            La troisième étape est de vérifier le titre de ces vidéos de
            synthèse sont souvent en majuscule, avec des points
            d'exclamation afin d'attirer le regard.
        </p>
        <p>
            La troisième étape est de vérifier les défauts de montage,
            portez votre attention sur les bordures du visage, il arrive parfois
            que des imperfections apparaissent.
        </p>
        <p>
            La dernière étape est de vérifier les sources, c'est la méthode la
            plus simple et la plus courrante pour déceler le vrai du faux.
        </p>

        <a href="https://cerfia.fr/deepfake-5-astuces-pour-les-demasquer/">Article de Cerfia</a>

        <h2>Ce que m'a appris l'article</h2>
        <p>
            Cette article permet de nous entrainer à repérer les "deepfake" pour lutter
            contre la désinformation et les dangers qu'ils représentent.
        </p>
    </article>
    <article>
        <h1>Un deepfake de Keanu reeves nous alerte contre les arnaques en ligne</h1>
        <img src="img/Deepfake_Keanu_Reeves.png" alt="Keanu Reeves dans une position de KungFu">
        <p>
            La banque HomeEquity, basée à Toronto, ont utilisé le visage de
            Keanu reeves, l'acteur charismatique de "Jhon Wick", dans plusieurs
            vidéos informatives contre les escroqueries en ligne.
        </p>
        <p>
            Ces vidéos ont été réalisé pour contrer la vraie arnaque nommé
            <strong>Keanu Reeves</strong> qui utilise le charisme de l'acteur pour
            faire des vidéos fake afin de tromper la confiance des internautes et leur
            faire dépenser leur argent dans des arnaques. D'après une étude de la Federal
            Trade Commission, les internautes auraient perdu 304 millions de dollars
            à cause de ce type d'arnaque.
        </p>
        <p>
            La banque cité plus haut a donc décidé d'utiliser le fonctionnement de
            la toute première arnaque pour prévenir ce genre d'arnaque.
        </p>

        <a href="https://lareclame.fr/zulualphakilo-homeequitybank-keanureeves-277871">Article de La réclame</a>

        <h2>Ce que m'a appris l'article</h2>
        <p>
            Cette article montre que certaine entreprise essaye de lutter contre
            les arnaques montées grace au "deepfake", ce qui pour moi est une bonne
            chose pour agir de manière préventive et éduquer la population
            à ce nouveau type d'arnaque et de technologie.
        </p>
    </article>
    <article>
        <h1>Tailor swift manipulé par ses fans</h1>
        <img src="img/deepTaylorSwift.png" alt="image Taylor swift">
        <p>
            Une intelligence artificielle qui réplique la chanteuse Taylor swift
            et qui est contrôlé par ses fans afin de faire des blagues. Ils ne sont, pour
            la plupart, pas mal intentionné a constaté la vraie Taylor swift.
            Il existe même des tutoriels pour répliquer leur star préférée.
        </p>
        <p>
            Ce n'est cependant pas le cas de tous les utilisateurs d'outils de deepfake
            et des utilisations malveillantes de ce genre d'outils pourrait créer de plus grave
            problème. Par exemple, si une réplique d'un dirigeant d'État était
            utilisé à des fins malveillantes et pourrait créer des incidents plus grave.
        </p>

        <a href="https://www.courrierinternational.com/article/deepfake-une-taylor-swift-de-synthese-egaie-ses-fanss">Article de Courrier International</a>

        <h2>Ce que m'a appris l'article</h2>
        <p>
            Cette article montre une utilisation innocente du "deepfake" mais pose
            également des questions quant à l'utilisation de ce genre d'outils pour
            de futur "deepfake".
        </p>
    </article>
    <article>
        <h1>L'IA le nouveau joué des escrocs</h1>
        <img src="img/escrocsDeepfake.jpeg" alt="homme avec un masque">
        <p>
            Si la fonction de base de ChatGPT est de répondre à vos questions
            afin de vous aider, les escrocs lui ont trouvé une tout autre utilité.
            Il l'utilise pour créer des chatBots, des "deepfake", des campagnes de pishing
            et des logiciels malveillants.
        </p>
        <p>
            Il existe différente utilisation de l'IA pour monter une escroquerie,
            par exemple ChatGPT pour créer des messages de pishing plus rapidement,
            Des IA comme ElevenLabs ou Midjourney pour créer des vidéos de personnalité
            connue imitée à la perfection ou pour simuler des appels téléphonique réaliste dans
            le but de vous estorquer de l'argent.
        </p>

        <a href="https://www.dynamique-mag.com/article/lia-un-nouvel-outil-pour-les-escrocs">Article de Dynamique Mag</a>

        <h2>Ce que m'a appris l'article</h2>
        <p>
            Les arnaques avec l'intelligence artificielle sont de plus en plus courante
            et ces technologies permettent d'en créer plus rapidement.
        </p>
    </article>
    <article>
        <h1>Les dirigeants d'État en folie</h1>
        <img src="img/macronDeepfake.jpeg" alt="Macron assis dans les poubelles">
        <p>
            Depuis plusieurs jours, nombreuses sont les images mettant en
            scène des dirigeants dans des situations caucasses et amusantes.
            Par exemple, Macron en train de ramasser les poubelles, Macron
            dans une manifestation, Trump arrêté par le FBI, etc.
        </p>
        <p>
            Toutes ces images ont été généré par l'intelligence artificielle
            Midjourney qui, depuis mars, a fait beaucoup de progrès et produit
            maintenant des images d'un réalisme epoustouflant.
            C'est outils permettant de créer facilement ce genre de contenu
            les internautes multiplient les images "fake". Même si la plupart
            des créateurs de ces photos indique que leurs images sont
            créées par une IA. On peut rapidement se dire que des dérives
            peuvent arriver très rapidement.
        </p>
        <p>
            Twitter et TikTok se sont donc engagé vérifier ces vidéos ou images
            et a apposé des avertissements dans le cas ou la manipualtion n'est pas
            spécifié.
        </p>

        <a href="https://www.bfmtv.com/tech/intelligence-artificielle/macron-en-eboueur-trump-en-prisonnier-quand-l-ia-cree-de-fausses-images-d-actualite-ultrarealistes_AD-202303220157.html">Article de BFMTV</a>

        <h2>Ce que m'a appris l'article</h2>
        <p>
            Cette article montre une utilisation sans réelles conséquences de l'intelligence
            artificielle en montrant du contenu humoristiques. Mais donne à réfléchir
            sur l'utilisation de ces technologies à but malveillant.
        </p>
    </article>
    <p id="signature">Revue de presse écrite par Quentin BEAUQUIER</p>
</section>
</body>
</html>